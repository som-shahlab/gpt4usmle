{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our approach for identifying poor-quality AI-generated exam items is by looking at the proportion of other (non-GPT4) models that selected the GPT4-selected \"correct\" answer. If the majority of a strong group of LLMs choose an answer other than the one that GPT-4 deems to be the \"correct\" answer, then that is evidence towards the GPT4-selected answer choice being \"incorrect\". Similarly, if there is no clear consensus among other LLM responses with respect to what the right answer choice should be, that is evidence that the GPT4-generated item may have flaws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['identifying_bad_ai_questions.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the data from Carina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are located on Carina `/share/pi/nigam/scottyf/ai_generated_questions.csv` and are generated by calling `inference_single_model.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "BioMistral-7B                   100\n",
       "Llama3-Med42-70B                100\n",
       "Llama3-OpenBioLLM-70B           100\n",
       "Meta-Llama-3-70B-Instruct       100\n",
       "Mistral-7B-Instruct-v0.3        100\n",
       "Mixtral-8x22B-Instruct-v0.1     100\n",
       "Phi-3-medium-4k-instruct        100\n",
       "Qwen2-72B-Instruct              100\n",
       "llama-2-70b-chat_huggingface    100\n",
       "med42-70b                       100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Located on Carina at /share/pi/nigam/scottyf/ai_generated_questions.csv\n",
    "ai_generated_questions = pd.read_csv(\"~/Documents/GitHub/gpt4usmle/data/ai_generated_questions.csv\")\n",
    "ai_generated_output = pd.read_csv(\"~/Documents/GitHub/gpt4usmle/data/ai_generated_questions_output_20240722.csv\")\n",
    "ai_generated_output.groupby(\"model\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_search(s):\n",
    "    match = re.search(r\"\\(([A-Z])\\)\", s)\n",
    "    if match:\n",
    "        return match[1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "ai_generated_output[\"candidate_answer_1\"] = (\n",
    "    ai_generated_output[\"model_answer\"]\n",
    "    .apply(lambda x: pattern_search(x))\n",
    ")\n",
    "\n",
    "ai_generated_output[\"candidate_answer_2\"] = (\n",
    "    ai_generated_output[\"model_answer\"]\n",
    "    .apply(lambda x: x.strip().strip(\"(\")[0] if not pd.isnull(x) else \"\")\n",
    ")\n",
    "\n",
    "ai_generated_output['final_answer'] = (\n",
    "    ai_generated_output['candidate_answer_1']\n",
    "    .fillna(ai_generated_output['candidate_answer_2'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_answer</th>\n",
       "      <th>candidate_answer_1</th>\n",
       "      <th>candidate_answer_2</th>\n",
       "      <th>final_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>D\\n)</td>\n",
       "      <td>None</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>A)</td>\n",
       "      <td>None</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>D)</td>\n",
       "      <td>None</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>D)\\n)</td>\n",
       "      <td>None</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>C\\n)</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>A)</td>\n",
       "      <td>None</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>E)\\nNo additional diagnostic studies are indic...</td>\n",
       "      <td>None</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>B)\\n thoracentesis is the most appropriate nex...</td>\n",
       "      <td>None</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>B\\n)</td>\n",
       "      <td>None</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>D)\\nSystemic lupus erythematosus</td>\n",
       "      <td>None</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_answer candidate_answer_1  \\\n",
       "100                                               D\\n)               None   \n",
       "101                                                 A)               None   \n",
       "102                                                 D)               None   \n",
       "103                                              D)\\n)               None   \n",
       "104                                               C\\n)               None   \n",
       "105                                                 A)               None   \n",
       "106  E)\\nNo additional diagnostic studies are indic...               None   \n",
       "107  B)\\n thoracentesis is the most appropriate nex...               None   \n",
       "108                                               B\\n)               None   \n",
       "109                   D)\\nSystemic lupus erythematosus               None   \n",
       "\n",
       "    candidate_answer_2 final_answer  \n",
       "100                  D            D  \n",
       "101                  A            A  \n",
       "102                  D            D  \n",
       "103                  D            D  \n",
       "104                  C            C  \n",
       "105                  A            A  \n",
       "106                  E            E  \n",
       "107                  B            B  \n",
       "108                  B            B  \n",
       "109                  D            D  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_generated_output.loc[\n",
    "    ai_generated_output[\"candidate_answer_1\"] != ai_generated_output[\"candidate_answer_2\"],\n",
    "    [\"model_answer\", \"candidate_answer_1\", \"candidate_answer_2\", \"final_answer\"]\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 7-year-old boy is brought to the physician because of a 1-year history of poor performance in school. His parents say that he is bright, has many friends, and seems to want to do well in school. His teachers report that he seems frustrated with his own progress and his inability to meet the expectations of his parents. Speech fluency and articulation and motor skills are appropriate for age. Physical examination shows no abnormalities. When asked to read during the examination, he has significant difficulty sounding out words he is unfamiliar with. Visual acuity test and audiometry show no abnormalities. Which of the following is the most likely diagnosis?\n",
      "\n",
      "(A) Attention-deficit/hyperactivity disorder\n",
      "(B) Expressive language disorder\n",
      "(C) Intellectual developmental disorder\n",
      "(D) Learning disorder\n",
      "(E) Social anxiety disorder (social phobia)\n",
      "(F) Normal behavior\n"
     ]
    }
   ],
   "source": [
    "print(ai_generated_questions[\"ItemText_Raw\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_generated_output.loc[ai_generated_output[\"model_answer\"].isnull(), \"model\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_num</th>\n",
       "      <th>gt_answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>candidate_answer_1</th>\n",
       "      <th>candidate_answer_2</th>\n",
       "      <th>final_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [item_num, gt_answer, model_answer, candidate_answer_1, candidate_answer_2, final_answer]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_generated_output.loc[ai_generated_output[\"model_answer\"].isnull(), :].groupby(\"model\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter down to just the best-performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>pct_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama3-Med42-70B</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meta-Llama-3-70B-Instruct</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mixtral-8x22B-Instruct-v0.1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qwen2-72B-Instruct</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama3-OpenBioLLM-70B</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phi-3-medium-4k-instruct</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>med42-70b</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama-2-70b-chat_huggingface</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BioMistral-7B</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  pct_correct\n",
       "1              Llama3-Med42-70B         0.80\n",
       "3     Meta-Llama-3-70B-Instruct         0.80\n",
       "5   Mixtral-8x22B-Instruct-v0.1         0.80\n",
       "7            Qwen2-72B-Instruct         0.80\n",
       "2         Llama3-OpenBioLLM-70B         0.76\n",
       "6      Phi-3-medium-4k-instruct         0.76\n",
       "9                     med42-70b         0.66\n",
       "8  llama-2-70b-chat_huggingface         0.60\n",
       "4      Mistral-7B-Instruct-v0.3         0.52\n",
       "0                 BioMistral-7B         0.28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_generated_questions = ai_generated_output.loc[ai_generated_output[\"item_num\"].str.endswith(\"H\"), :].copy()\n",
    "human_generated_questions[\"model_is_correct\"] = human_generated_questions[\"final_answer\"] == human_generated_questions[\"gt_answer\"]\n",
    "model_perf_df = (\n",
    "    human_generated_questions\n",
    "    .groupby(\"model\")\n",
    "    .agg(pct_correct = (\"model_is_correct\", \"mean\"))\n",
    "    .reset_index()\n",
    "    .sort_values(\"pct_correct\", ascending=False)\n",
    ")\n",
    "model_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_generated_output = ai_generated_output[\n",
    "    ai_generated_output['model'].isin([\n",
    "        # 'Qwen1.5-72B-Chat', \n",
    "        # 'Mixtral-8x7B-Instruct-v0.1', \n",
    "        # 'Mistral-7B-Instruct-v0.2', \n",
    "        # 'zephyr-7b-beta'\n",
    "        \n",
    "        # \"Llama3-Med42-70B\",\n",
    "        \"Meta-Llama-3-70B-Instruct\",\n",
    "        \"Mixtral-8x22B-Instruct-v0.1\",\n",
    "        \"Qwen2-72B-Instruct\",\n",
    "        # \"Llama3-OpenBioLLM-70B\",\n",
    "        \"Phi-3-medium-4k-instruct\",\n",
    "        # \"med42-70b\",\n",
    "        \"llama-2-70b-chat_huggingface\",\n",
    "        # \"Mistral-7B-Instruct-v0.3\"\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define what is a \"good\" vs. \"bad\" AI-generated question using clinician labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had 2 clinicians review each AI-generated question and decide whether it was a \"good\" question or a \"bad\" question. Often there was consensus, but sometimes it was 50/50. For this analysis, we take the view that if *any* clinician deemed that an AI-generated question was \"bad\" then it was indeed \"bad\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemNum</th>\n",
       "      <th>true_human_or_GPT4</th>\n",
       "      <th>ItemText_Raw</th>\n",
       "      <th>is_bad_strict</th>\n",
       "      <th>is_bad_relaxed</th>\n",
       "      <th>consensus_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>059G</td>\n",
       "      <td>GPT</td>\n",
       "      <td>A 27-year-old woman visits her primary care ph...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Multiple correct answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>110H</td>\n",
       "      <td>human</td>\n",
       "      <td>A 45-year-old man is brought to the emergency ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>065H</td>\n",
       "      <td>human</td>\n",
       "      <td>A 2-week-old boy is evaluated in the neonatal ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>028G</td>\n",
       "      <td>GPT</td>\n",
       "      <td>A 35-year-old woman presents to the emergency ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AI-chosen answer is incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>091G</td>\n",
       "      <td>GPT</td>\n",
       "      <td>A 65-year-old man presents to the primary care...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Multiple correct answers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemNum true_human_or_GPT4  \\\n",
       "95    059G                GPT   \n",
       "96    110H              human   \n",
       "97    065H              human   \n",
       "98    028G                GPT   \n",
       "99    091G                GPT   \n",
       "\n",
       "                                         ItemText_Raw  is_bad_strict  \\\n",
       "95  A 27-year-old woman visits her primary care ph...          False   \n",
       "96  A 45-year-old man is brought to the emergency ...          False   \n",
       "97  A 2-week-old boy is evaluated in the neonatal ...          False   \n",
       "98  A 35-year-old woman presents to the emergency ...          False   \n",
       "99  A 65-year-old man presents to the primary care...           True   \n",
       "\n",
       "    is_bad_relaxed               consensus_reason  \n",
       "95            True       Multiple correct answers  \n",
       "96           False                            NaN  \n",
       "97           False                            NaN  \n",
       "98            True  AI-chosen answer is incorrect  \n",
       "99            True       Multiple correct answers  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_good_qa = ai_generated_questions[['ItemNum', 'true_human_or_GPT4', 'ItemText_Raw']].copy()\n",
    "is_good_qa['is_bad_strict'] = ai_generated_questions['consensus_is_gpt_qa_correct'] == 'no'\n",
    "is_good_qa['is_bad_relaxed'] = ai_generated_questions['consensus_is_gpt_qa_correct'].isin(['no', '50/50'])\n",
    "is_good_qa['consensus_reason'] = ai_generated_questions['consensus_reason']\n",
    "is_good_qa.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate proportion of models that selected each answer choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_num</th>\n",
       "      <th>prop_A</th>\n",
       "      <th>prop_B</th>\n",
       "      <th>prop_C</th>\n",
       "      <th>prop_D</th>\n",
       "      <th>prop_E</th>\n",
       "      <th>prop_F</th>\n",
       "      <th>prop_G</th>\n",
       "      <th>prop_H</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>ItemNum</th>\n",
       "      <th>true_human_or_GPT4</th>\n",
       "      <th>ItemText_Raw</th>\n",
       "      <th>is_bad_strict</th>\n",
       "      <th>is_bad_relaxed</th>\n",
       "      <th>consensus_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006G</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>006G</td>\n",
       "      <td>GPT</td>\n",
       "      <td>A 36-year-old man presents to the emergency de...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Multiple correct answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>006H</td>\n",
       "      <td>human</td>\n",
       "      <td>A previously healthy 29-year-old woman is admi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007G</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>007G</td>\n",
       "      <td>GPT</td>\n",
       "      <td>A 32-year-old gravida 2, para 1 woman presents...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>007H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>007H</td>\n",
       "      <td>human</td>\n",
       "      <td>A 27-year-old primigravid woman comes to the p...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009G</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>009G</td>\n",
       "      <td>GPT</td>\n",
       "      <td>A 45-year-old woman presents to the emergency ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_num  prop_A  prop_B  prop_C  prop_D  prop_E  prop_F  prop_G  prop_H  \\\n",
       "0     006G     0.0     0.8     0.2     0.0     0.0     0.0     0.0     0.0   \n",
       "1     006H     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     007G     0.0     0.0     0.0     0.8     0.2     0.0     0.0     0.0   \n",
       "3     007H     0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "4     009G     0.0     0.4     0.4     0.2     0.0     0.0     0.0     0.0   \n",
       "\n",
       "  correct_answer ItemNum true_human_or_GPT4  \\\n",
       "0              B    006G                GPT   \n",
       "1              A    006H              human   \n",
       "2              D    007G                GPT   \n",
       "3              D    007H              human   \n",
       "4              B    009G                GPT   \n",
       "\n",
       "                                        ItemText_Raw  is_bad_strict  \\\n",
       "0  A 36-year-old man presents to the emergency de...           True   \n",
       "1  A previously healthy 29-year-old woman is admi...          False   \n",
       "2  A 32-year-old gravida 2, para 1 woman presents...          False   \n",
       "3  A 27-year-old primigravid woman comes to the p...          False   \n",
       "4  A 45-year-old woman presents to the emergency ...          False   \n",
       "\n",
       "   is_bad_relaxed          consensus_reason  \n",
       "0            True  Multiple correct answers  \n",
       "1           False                       NaN  \n",
       "2           False                       NaN  \n",
       "3           False                       NaN  \n",
       "4           False                       NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_questions_answer_probabilities_df = ai_generated_output.groupby('item_num').agg(\n",
    "    prop_A = ('final_answer', lambda x: (x == 'A').mean()),\n",
    "    prop_B = ('final_answer', lambda x: (x == 'B').mean()),\n",
    "    prop_C = ('final_answer', lambda x: (x == 'C').mean()),\n",
    "    prop_D = ('final_answer', lambda x: (x == 'D').mean()),\n",
    "    prop_E = ('final_answer', lambda x: (x == 'E').mean()),\n",
    "    prop_F = ('final_answer', lambda x: (x == 'F').mean()),\n",
    "    prop_G = ('final_answer', lambda x: (x == 'G').mean()),\n",
    "    prop_H = ('final_answer', lambda x: (x == 'H').mean()),\n",
    "    correct_answer = ('gt_answer', 'first')\n",
    ")\n",
    "ai_questions_answer_probabilities_df = (\n",
    "    ai_questions_answer_probabilities_df\n",
    "    .reset_index()\n",
    "    .merge(is_good_qa, left_on='item_num', right_on='ItemNum')\n",
    ")\n",
    "ai_questions_answer_probabilities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate proportion of LLMs that selected the GPT4-selected \"Answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemNum</th>\n",
       "      <th>ItemText_Raw</th>\n",
       "      <th>majority_vote</th>\n",
       "      <th>prop_llms_in_majority</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>prop_llms_correct</th>\n",
       "      <th>true_human_or_GPT4</th>\n",
       "      <th>is_bad_strict</th>\n",
       "      <th>is_bad_relaxed</th>\n",
       "      <th>consensus_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>111G</td>\n",
       "      <td>A 27-year-old woman presents to the clinic wit...</td>\n",
       "      <td>B</td>\n",
       "      <td>0.4</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GPT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>No correct answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>043G</td>\n",
       "      <td>A 62-year-old woman presents to the clinic wit...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GPT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AI-chosen answer is incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>063G</td>\n",
       "      <td>A 28-year-old woman, gravida 3, para 3, presen...</td>\n",
       "      <td>D</td>\n",
       "      <td>0.8</td>\n",
       "      <td>E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GPT</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>AI-chosen answer is incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>075G</td>\n",
       "      <td>A 12-year-old boy is brought to the pediatrici...</td>\n",
       "      <td>D</td>\n",
       "      <td>0.8</td>\n",
       "      <td>C</td>\n",
       "      <td>0.2</td>\n",
       "      <td>GPT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>061G</td>\n",
       "      <td>A 56-year-old man presents to the clinic with ...</td>\n",
       "      <td>A</td>\n",
       "      <td>0.8</td>\n",
       "      <td>E</td>\n",
       "      <td>0.2</td>\n",
       "      <td>GPT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Multiple correct answers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemNum                                       ItemText_Raw majority_vote  \\\n",
       "46    111G  A 27-year-old woman presents to the clinic wit...             B   \n",
       "15    043G  A 62-year-old woman presents to the clinic wit...             C   \n",
       "22    063G  A 28-year-old woman, gravida 3, para 3, presen...             D   \n",
       "29    075G  A 12-year-old boy is brought to the pediatrici...             D   \n",
       "20    061G  A 56-year-old man presents to the clinic with ...             A   \n",
       "\n",
       "    prop_llms_in_majority correct_answer  prop_llms_correct  \\\n",
       "46                    0.4              A                0.0   \n",
       "15                    1.0              A                0.0   \n",
       "22                    0.8              E                0.0   \n",
       "29                    0.8              C                0.2   \n",
       "20                    0.8              E                0.2   \n",
       "\n",
       "   true_human_or_GPT4  is_bad_strict  is_bad_relaxed  \\\n",
       "46                GPT          False            True   \n",
       "15                GPT          False            True   \n",
       "22                GPT           True            True   \n",
       "29                GPT          False           False   \n",
       "20                GPT          False            True   \n",
       "\n",
       "                 consensus_reason  \n",
       "46              No correct answer  \n",
       "15  AI-chosen answer is incorrect  \n",
       "22  AI-chosen answer is incorrect  \n",
       "29                            NaN  \n",
       "20       Multiple correct answers  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_questions_llm_response_probs_df = []\n",
    "\n",
    "for i, row in ai_questions_answer_probabilities_df.iterrows():\n",
    "    if row['true_human_or_GPT4'] == 'human':\n",
    "        continue\n",
    "    majority_vote = None\n",
    "    max_vote = -np.inf\n",
    "    for answer_choice in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']:\n",
    "        if row[f'prop_{answer_choice}'] > max_vote:\n",
    "            majority_vote = answer_choice\n",
    "            max_vote = row[f'prop_{answer_choice}']\n",
    "    the_correct_answer = row['correct_answer']\n",
    "    new_row = {\n",
    "        'ItemNum': row['ItemNum'],\n",
    "        'ItemText_Raw': row['ItemText_Raw'],\n",
    "        'majority_vote': majority_vote,\n",
    "        'prop_llms_in_majority': max_vote,\n",
    "        'correct_answer': the_correct_answer,\n",
    "        'prop_llms_correct': row[f'prop_{the_correct_answer}'],\n",
    "        'true_human_or_GPT4': row['true_human_or_GPT4'],\n",
    "        'is_bad_strict': row['is_bad_strict'],\n",
    "        'is_bad_relaxed': row['is_bad_relaxed'],\n",
    "        'consensus_reason': row['consensus_reason']\n",
    "    }\n",
    "    ai_questions_llm_response_probs_df.append(new_row)\n",
    "\n",
    "ai_questions_llm_response_probs_df = pd.DataFrame(ai_questions_llm_response_probs_df).sort_values('prop_llms_correct')\n",
    "ai_questions_llm_response_probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = \"is_bad_strict\"\n",
    "target = \"is_bad_relaxed\"\n",
    "metric = \"prop_llms_correct\"\n",
    "# metric = \"prop_llms_in_majority\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 1, 11)\n",
    "plt.hist(\n",
    "    ai_questions_llm_response_probs_df.loc[ai_questions_llm_response_probs_df[target] == 1, metric],\n",
    "    bins=bins,\n",
    "    color='tab:red',\n",
    "    alpha=0.3,\n",
    "    label='Poor Quality AI-Generated Exam Items',\n",
    "    density=True\n",
    ")\n",
    "plt.hist(\n",
    "    ai_questions_llm_response_probs_df.loc[ai_questions_llm_response_probs_df[target] == 0, metric],\n",
    "    bins=bins,\n",
    "    color='tab:green',\n",
    "    alpha=0.3,\n",
    "    label='High Quality AI-Generated Exam Items',\n",
    "    density=True\n",
    ")\n",
    "plt.title('Distribution of model responses in realistic setting')\n",
    "plt.xlabel('Proportion of LLMs selecting the correct answer')\n",
    "plt.ylabel('Number of AI-generated exam items')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify AI-generated as good vs. bad based on proportion of LLMs that selected GPT4-chosen answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ability of LLM ensemble to detect poor quality AI-generated questions in realistic setting\n",
      "threshold=0.01, precision=0.60, recall=0.83\n",
      "threshold=0.11, precision=0.60, recall=0.83\n",
      "threshold=0.21, precision=0.64, recall=0.50\n",
      "threshold=0.31, precision=0.64, recall=0.50\n",
      "threshold=0.41, precision=0.73, recall=0.44\n",
      "threshold=0.51, precision=0.73, recall=0.44\n",
      "threshold=0.60, precision=0.67, recall=0.22\n",
      "threshold=0.70, precision=0.67, recall=0.22\n",
      "threshold=0.80, precision=1.00, recall=0.17\n",
      "threshold=0.90, precision=1.00, recall=0.17\n",
      "threshold=1.00, precision=0.00, recall=0.00\n",
      "AUROC = 0.7864583333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottyf/anaconda3/envs/youper/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Ability of LLM ensemble to detect poor quality AI-generated questions in realistic setting\")\n",
    "for thresh in np.linspace(0.01, 1, 11):\n",
    "    y_true = ai_questions_llm_response_probs_df[target]  # Whether the answer choice was incorrect\n",
    "    # y_pred = ai_questions_llm_response_probs_df['prop_llms_in_majority'] < thresh\n",
    "    y_pred = (1-ai_questions_llm_response_probs_df[metric]) > thresh\n",
    "    # y_pred = np.logical_and(\n",
    "    #     ai_questions_llm_response_probs_df['prop_llms_in_majority'] < thresh, \n",
    "    #     ai_questions_llm_response_probs_df['prop_llms_correct'] < thresh, \n",
    "    # )\n",
    "    precision = precision_score(y_true=y_true, y_pred=y_pred)\n",
    "    recall = recall_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f\"threshold={thresh:.2f}, precision={precision:.2f}, recall={recall:.2f}\")\n",
    "\n",
    "auroc = roc_auc_score(\n",
    "    ai_questions_llm_response_probs_df[target], \n",
    "    1-ai_questions_llm_response_probs_df[metric]\n",
    ")\n",
    "print(f\"AUROC = {auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num AI-generated questions that are actually bad = 18\n",
      "Num AI-generated questions that are predicted bad = 25\n",
      "threshold=0.80, precision=0.60, recall=0.83\n"
     ]
    }
   ],
   "source": [
    "thresh = 0.80\n",
    "y_true = ai_questions_llm_response_probs_df[target]\n",
    "y_pred = ai_questions_llm_response_probs_df[metric] <= thresh\n",
    "precision = precision_score(y_true=y_true, y_pred=y_pred)\n",
    "recall = recall_score(y_true=y_true, y_pred=y_pred)\n",
    "print(f\"Num AI-generated questions that are actually bad = {y_true.sum()}\")\n",
    "print(f\"Num AI-generated questions that are predicted bad = {y_pred.sum()}\")\n",
    "print(f\"threshold={thresh:.2f}, precision={precision:.2f}, recall={recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We said the question was not fine but it was actually fine\n",
    "false_positives = ai_questions_llm_response_probs_df.loc[\n",
    "    (ai_questions_llm_response_probs_df[metric] <= thresh) &\n",
    "    (ai_questions_llm_response_probs_df[\"is_bad_relaxed\"] == False)\n",
    "]\n",
    "len(false_positives)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We said the question was not fine \n",
    "true_positives = ai_questions_llm_response_probs_df.loc[\n",
    "    (ai_questions_llm_response_probs_df[metric] <= thresh) &\n",
    "    (ai_questions_llm_response_probs_df[\"is_bad_relaxed\"] == True)\n",
    "]\n",
    "len(true_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15 / (15 + 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We said the question was fine and it was fine\n",
    "true_negatives = ai_questions_llm_response_probs_df.loc[\n",
    "    (ai_questions_llm_response_probs_df[metric] > thresh) &\n",
    "    (ai_questions_llm_response_probs_df[\"is_bad_relaxed\"] == False)\n",
    "]\n",
    "len(true_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We said the question was fine but it actually had problems\n",
    "false_negatives = ai_questions_llm_response_probs_df.loc[\n",
    "    (ai_questions_llm_response_probs_df[metric] > thresh) &\n",
    "    (ai_questions_llm_response_probs_df[\"is_bad_relaxed\"] == True)\n",
    "]\n",
    "len(false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemNum</th>\n",
       "      <th>ItemText_Raw</th>\n",
       "      <th>majority_vote</th>\n",
       "      <th>prop_llms_in_majority</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>prop_llms_correct</th>\n",
       "      <th>true_human_or_GPT4</th>\n",
       "      <th>is_bad_strict</th>\n",
       "      <th>is_bad_relaxed</th>\n",
       "      <th>consensus_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>104G</td>\n",
       "      <td>A 36-year-old woman presents to the clinic wit...</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GPT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Multiple correct answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>028G</td>\n",
       "      <td>A 35-year-old woman presents to the emergency ...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GPT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AI-chosen answer is incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>091G</td>\n",
       "      <td>A 65-year-old man presents to the primary care...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GPT</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Multiple correct answers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemNum                                       ItemText_Raw majority_vote  \\\n",
       "42    104G  A 36-year-old woman presents to the clinic wit...             B   \n",
       "6     028G  A 35-year-old woman presents to the emergency ...             C   \n",
       "36    091G  A 65-year-old man presents to the primary care...             C   \n",
       "\n",
       "    prop_llms_in_majority correct_answer  prop_llms_correct  \\\n",
       "42                    1.0              B                1.0   \n",
       "6                     1.0              C                1.0   \n",
       "36                    1.0              C                1.0   \n",
       "\n",
       "   true_human_or_GPT4  is_bad_strict  is_bad_relaxed  \\\n",
       "42                GPT          False            True   \n",
       "6                 GPT          False            True   \n",
       "36                GPT           True            True   \n",
       "\n",
       "                 consensus_reason  \n",
       "42       Multiple correct answers  \n",
       "6   AI-chosen answer is incorrect  \n",
       "36       Multiple correct answers  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 35-year-old woman presents to the emergency department with severe abdominal pain and vomiting for the past 6 hours. She reports that the pain started suddenly and is located in the right lower quadrant. She has no significant past medical history and is not currently taking any medications. She has no known drug allergies. She is 165 cm (5 ft 5 in) tall and weighs 68 kg (150 lb); BMI is 25 kg/m². Temperature is 38.2°C (100.8°F), pulse is 110/min, respirations are 20/min, and blood pressure is 115/75 mm Hg. Physical examination reveals rebound tenderness and guarding in the right lower quadrant. Laboratory studies show a white blood cell count of 15,000/mm³. Which of the following is the most appropriate next step in management?\n",
      "\n",
      "(A) Administer intravenous fluids and antiemetics\n",
      "(B) Administer intravenous morphine for pain control\n",
      "(C) Obtain a surgical consultation for suspected appendicitis\n",
      "(D) Perform an abdominal ultrasound\n",
      "(E) Prescribe oral antibiotics for suspected gastroenteritis\n"
     ]
    }
   ],
   "source": [
    "print(ai_questions_llm_response_probs_df.loc[\n",
    "    ai_questions_llm_response_probs_df[\"ItemNum\"] == \"028G\",\n",
    "    \"ItemText_Raw\"\n",
    "].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 65-year-old man presents to the primary care clinic for a follow-up visit after being discharged from the hospital 1 week ago due to a myocardial infarction. The patient has a history of type 2 diabetes mellitus and hypertension, which are managed with metformin, lisinopril, and hydrochlorothiazide. Since discharge, he has been prescribed atorvastatin, metoprolol, and aspirin. He reports mild shortness of breath on exertion and occasional chest discomfort. Vital signs reveal a temperature of 36.7°C (98.1°F), pulse of 68/min, respirations of 16/min, and blood pressure of 128/78 mm Hg. Cardiac examination shows regular rate and rhythm with no murmurs, rubs, or gallops. Pulmonary examination reveals clear breath sounds bilaterally. Laboratory results show a fasting glucose level of 140 mg/dL, HbA1c of 7.8%, and a lipid panel with an LDL cholesterol of 100 mg/dL. The patient lives alone, but his adult children live nearby and visit him regularly. What is the most appropriate next step in management?\n",
      "\n",
      "(A) Increase the dose of metformin and add a sulfonylurea\n",
      "(B) Add an angiotensin receptor blocker to his medication regimen\n",
      "(C) Refer the patient for a cardiac rehabilitation program\n",
      "(D) Prescribe a long-acting nitrate for the management of chest discomfort\n"
     ]
    }
   ],
   "source": [
    "print(ai_questions_llm_response_probs_df.loc[\n",
    "    ai_questions_llm_response_probs_df[\"ItemNum\"] == \"091G\",\n",
    "    \"ItemText_Raw\"\n",
    "].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
