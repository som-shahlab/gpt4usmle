{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our approach for identifying poor-quality AI-generated exam items is by looking at the proportion of other (non-GPT4) models that selected the GPT4-selected \"correct\" answer. If the majority of a strong group of LLMs choose an answer other than the one that GPT-4 deems to be the \"correct\" answer, then that is evidence towards the GPT4-selected answer choice being \"incorrect\". Similarly, if there is no clear consensus among other LLM responses with respect to what the right answer choice should be, that is evidence that the GPT4-generated item may have flaws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the data from Carina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are located on Carina `/share/pi/nigam/scottyf/ai_generated_questions.csv` and are generated by calling `inference_single_model.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Qwen1.5-72B-Chat', 'Mixtral-8x7B-Instruct-v0.1',\n",
       "       'Mistral-7B-Instruct-v0.2', 'Mistral-7B-Instruct-v0.1',\n",
       "       'zephyr-7b-beta', 'llama-2-7b-chat_huggingface',\n",
       "       'llama-2-13b-chat_huggingface', 'AlpaCare-llama2-7b',\n",
       "       'AlpaCare-llama2-13b'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Located on Carina at /share/pi/nigam/scottyf/ai_generated_questions.csv\n",
    "ai_generated_questions = pd.read_csv(\"~/Downloads/ai_generated_questions.csv\")\n",
    "ai_generated_output = pd.read_csv(\"~/Downloads/ai_generated_questions_output.csv\")\n",
    "ai_generated_output['model'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter down to just the best-performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>pct_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Qwen1.5-72B-Chat</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mixtral-8x7B-Instruct-v0.1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlpaCare-llama2-13b</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AlpaCare-llama2-7b</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama-2-13b-chat_huggingface</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama-2-7b-chat_huggingface</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  pct_correct\n",
       "5              Qwen1.5-72B-Chat         0.78\n",
       "4    Mixtral-8x7B-Instruct-v0.1         0.72\n",
       "3      Mistral-7B-Instruct-v0.2         0.56\n",
       "8                zephyr-7b-beta         0.54\n",
       "0           AlpaCare-llama2-13b         0.50\n",
       "2      Mistral-7B-Instruct-v0.1         0.46\n",
       "1            AlpaCare-llama2-7b         0.38\n",
       "6  llama-2-13b-chat_huggingface         0.38\n",
       "7   llama-2-7b-chat_huggingface         0.34"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_generated_questions = ai_generated_output.loc[ai_generated_output[\"item_num\"].str.endswith(\"H\"), :].copy()\n",
    "human_generated_questions[\"model_is_correct\"] = human_generated_questions[\"model_answer\"] == human_generated_questions[\"gt_answer\"]\n",
    "model_perf_df = (\n",
    "    human_generated_questions\n",
    "    .groupby(\"model\")\n",
    "    .agg(pct_correct = (\"model_is_correct\", \"mean\"))\n",
    "    .reset_index()\n",
    "    .sort_values(\"pct_correct\", ascending=False)\n",
    ")\n",
    "model_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_generated_output = ai_generated_output[\n",
    "    ai_generated_output['model'].isin([\n",
    "        'Qwen1.5-72B-Chat', \n",
    "        'Mixtral-8x7B-Instruct-v0.1', \n",
    "        'Mistral-7B-Instruct-v0.2', \n",
    "        'zephyr-7b-beta'\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define what is a \"good\" vs. \"bad\" AI-generated question using clinician labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had 2 clinicians review each AI-generated question and decide whether it was a \"good\" question or a \"bad\" question. Often there was consensus, but sometimes it was 50/50. For this analysis, we take the view that if *any* clinician deemed that an AI-generated question was \"bad\" then it was indeed \"bad\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemNum</th>\n",
       "      <th>true_human_or_GPT4</th>\n",
       "      <th>ItemText_Raw</th>\n",
       "      <th>is_bad_strict</th>\n",
       "      <th>is_bad_relaxed</th>\n",
       "      <th>consensus_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>059G</td>\n",
       "      <td>GPT</td>\n",
       "      <td>A 27-year-old woman visits her primary care ph...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Multiple correct answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>110H</td>\n",
       "      <td>human</td>\n",
       "      <td>A 45-year-old man is brought to the emergency ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>065H</td>\n",
       "      <td>human</td>\n",
       "      <td>A 2-week-old boy is evaluated in the neonatal ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>028G</td>\n",
       "      <td>GPT</td>\n",
       "      <td>A 35-year-old woman presents to the emergency ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AI-chosen answer is incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>091G</td>\n",
       "      <td>GPT</td>\n",
       "      <td>A 65-year-old man presents to the primary care...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Multiple correct answers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemNum true_human_or_GPT4  \\\n",
       "95    059G                GPT   \n",
       "96    110H              human   \n",
       "97    065H              human   \n",
       "98    028G                GPT   \n",
       "99    091G                GPT   \n",
       "\n",
       "                                         ItemText_Raw  is_bad_strict  \\\n",
       "95  A 27-year-old woman visits her primary care ph...          False   \n",
       "96  A 45-year-old man is brought to the emergency ...          False   \n",
       "97  A 2-week-old boy is evaluated in the neonatal ...          False   \n",
       "98  A 35-year-old woman presents to the emergency ...          False   \n",
       "99  A 65-year-old man presents to the primary care...           True   \n",
       "\n",
       "    is_bad_relaxed               consensus_reason  \n",
       "95            True       Multiple correct answers  \n",
       "96           False                            NaN  \n",
       "97           False                            NaN  \n",
       "98            True  AI-chosen answer is incorrect  \n",
       "99            True       Multiple correct answers  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_good_qa = ai_generated_questions[['ItemNum', 'true_human_or_GPT4', 'ItemText_Raw']].copy()\n",
    "is_good_qa['is_bad_strict'] = ai_generated_questions['consensus_is_gpt_qa_correct'] == 'no'\n",
    "is_good_qa['is_bad_relaxed'] = ai_generated_questions['consensus_is_gpt_qa_correct'].isin(['no', '50/50'])\n",
    "is_good_qa['consensus_reason'] = ai_generated_questions['consensus_reason']\n",
    "is_good_qa.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate proportion of models that selected each answer choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_num</th>\n",
       "      <th>prop_A</th>\n",
       "      <th>prop_B</th>\n",
       "      <th>prop_C</th>\n",
       "      <th>prop_D</th>\n",
       "      <th>prop_E</th>\n",
       "      <th>prop_F</th>\n",
       "      <th>prop_G</th>\n",
       "      <th>prop_H</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>ItemNum</th>\n",
       "      <th>true_human_or_GPT4</th>\n",
       "      <th>ItemText_Raw</th>\n",
       "      <th>is_bad_strict</th>\n",
       "      <th>is_bad_relaxed</th>\n",
       "      <th>consensus_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006G</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>006G</td>\n",
       "      <td>GPT</td>\n",
       "      <td>A 36-year-old man presents to the emergency de...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Multiple correct answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>006H</td>\n",
       "      <td>human</td>\n",
       "      <td>A previously healthy 29-year-old woman is admi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007G</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>007G</td>\n",
       "      <td>GPT</td>\n",
       "      <td>A 32-year-old gravida 2, para 1 woman presents...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>007H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>007H</td>\n",
       "      <td>human</td>\n",
       "      <td>A 27-year-old primigravid woman comes to the p...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009G</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>009G</td>\n",
       "      <td>GPT</td>\n",
       "      <td>A 45-year-old woman presents to the emergency ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_num  prop_A  prop_B  prop_C  prop_D  prop_E  prop_F  prop_G  prop_H  \\\n",
       "0     006G     0.0    0.50     0.0    0.00     0.5     0.0     0.0     0.0   \n",
       "1     006H     1.0    0.00     0.0    0.00     0.0     0.0     0.0     0.0   \n",
       "2     007G     0.0    0.25     0.0    0.75     0.0     0.0     0.0     0.0   \n",
       "3     007H     0.0    0.75     0.0    0.25     0.0     0.0     0.0     0.0   \n",
       "4     009G     0.0    0.75     0.0    0.25     0.0     0.0     0.0     0.0   \n",
       "\n",
       "  correct_answer ItemNum true_human_or_GPT4  \\\n",
       "0              B    006G                GPT   \n",
       "1              A    006H              human   \n",
       "2              D    007G                GPT   \n",
       "3              D    007H              human   \n",
       "4              B    009G                GPT   \n",
       "\n",
       "                                        ItemText_Raw  is_bad_strict  \\\n",
       "0  A 36-year-old man presents to the emergency de...           True   \n",
       "1  A previously healthy 29-year-old woman is admi...          False   \n",
       "2  A 32-year-old gravida 2, para 1 woman presents...          False   \n",
       "3  A 27-year-old primigravid woman comes to the p...          False   \n",
       "4  A 45-year-old woman presents to the emergency ...          False   \n",
       "\n",
       "   is_bad_relaxed          consensus_reason  \n",
       "0            True  Multiple correct answers  \n",
       "1           False                       NaN  \n",
       "2           False                       NaN  \n",
       "3           False                       NaN  \n",
       "4           False                       NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_questions_answer_probabilities_df = ai_generated_output.groupby('item_num').agg(\n",
    "    prop_A = ('model_answer', lambda x: (x == 'A').mean()),\n",
    "    prop_B = ('model_answer', lambda x: (x == 'B').mean()),\n",
    "    prop_C = ('model_answer', lambda x: (x == 'C').mean()),\n",
    "    prop_D = ('model_answer', lambda x: (x == 'D').mean()),\n",
    "    prop_E = ('model_answer', lambda x: (x == 'E').mean()),\n",
    "    prop_F = ('model_answer', lambda x: (x == 'F').mean()),\n",
    "    prop_G = ('model_answer', lambda x: (x == 'G').mean()),\n",
    "    prop_H = ('model_answer', lambda x: (x == 'H').mean()),\n",
    "    correct_answer = ('gt_answer', 'first')\n",
    ")\n",
    "ai_questions_answer_probabilities_df = (\n",
    "    ai_questions_answer_probabilities_df\n",
    "    .reset_index()\n",
    "    .merge(is_good_qa, left_on='item_num', right_on='ItemNum')\n",
    ")\n",
    "ai_questions_answer_probabilities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate proportion of LLMs that selected the GPT4-selected \"Answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemNum</th>\n",
       "      <th>ItemText_Raw</th>\n",
       "      <th>majority_vote</th>\n",
       "      <th>prop_llms_in_majority</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>prop_llms_correct</th>\n",
       "      <th>true_human_or_GPT4</th>\n",
       "      <th>is_bad_strict</th>\n",
       "      <th>is_bad_relaxed</th>\n",
       "      <th>consensus_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>111G</td>\n",
       "      <td>A 27-year-old woman presents to the clinic wit...</td>\n",
       "      <td>D</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "      <td>GPT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>No correct answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>075G</td>\n",
       "      <td>A 12-year-old boy is brought to the pediatrici...</td>\n",
       "      <td>D</td>\n",
       "      <td>1.00</td>\n",
       "      <td>C</td>\n",
       "      <td>0.00</td>\n",
       "      <td>GPT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>068G</td>\n",
       "      <td>A 45-year-old man presents to the clinic with ...</td>\n",
       "      <td>B</td>\n",
       "      <td>0.75</td>\n",
       "      <td>C</td>\n",
       "      <td>0.00</td>\n",
       "      <td>GPT</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Multiple correct answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>043G</td>\n",
       "      <td>A 62-year-old woman presents to the clinic wit...</td>\n",
       "      <td>C</td>\n",
       "      <td>1.00</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "      <td>GPT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AI-chosen answer is incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>063G</td>\n",
       "      <td>A 28-year-old woman, gravida 3, para 3, presen...</td>\n",
       "      <td>D</td>\n",
       "      <td>0.50</td>\n",
       "      <td>E</td>\n",
       "      <td>0.25</td>\n",
       "      <td>GPT</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>AI-chosen answer is incorrect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemNum                                       ItemText_Raw majority_vote  \\\n",
       "46    111G  A 27-year-old woman presents to the clinic wit...             D   \n",
       "29    075G  A 12-year-old boy is brought to the pediatrici...             D   \n",
       "26    068G  A 45-year-old man presents to the clinic with ...             B   \n",
       "15    043G  A 62-year-old woman presents to the clinic wit...             C   \n",
       "22    063G  A 28-year-old woman, gravida 3, para 3, presen...             D   \n",
       "\n",
       "    prop_llms_in_majority correct_answer  prop_llms_correct  \\\n",
       "46                   0.75              A               0.00   \n",
       "29                   1.00              C               0.00   \n",
       "26                   0.75              C               0.00   \n",
       "15                   1.00              A               0.00   \n",
       "22                   0.50              E               0.25   \n",
       "\n",
       "   true_human_or_GPT4  is_bad_strict  is_bad_relaxed  \\\n",
       "46                GPT          False            True   \n",
       "29                GPT          False           False   \n",
       "26                GPT           True            True   \n",
       "15                GPT          False            True   \n",
       "22                GPT           True            True   \n",
       "\n",
       "                 consensus_reason  \n",
       "46              No correct answer  \n",
       "29                            NaN  \n",
       "26       Multiple correct answers  \n",
       "15  AI-chosen answer is incorrect  \n",
       "22  AI-chosen answer is incorrect  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_questions_llm_response_probs_df = []\n",
    "\n",
    "for i, row in ai_questions_answer_probabilities_df.iterrows():\n",
    "    if row['true_human_or_GPT4'] == 'human':\n",
    "        continue\n",
    "    majority_vote = None\n",
    "    max_vote = -np.inf\n",
    "    for answer_choice in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']:\n",
    "        if row[f'prop_{answer_choice}'] > max_vote:\n",
    "            majority_vote = answer_choice\n",
    "            max_vote = row[f'prop_{answer_choice}']\n",
    "    the_correct_answer = row['correct_answer']\n",
    "    new_row = {\n",
    "        'ItemNum': row['ItemNum'],\n",
    "        'ItemText_Raw': row['ItemText_Raw'],\n",
    "        'majority_vote': majority_vote,\n",
    "        'prop_llms_in_majority': max_vote,\n",
    "        'correct_answer': the_correct_answer,\n",
    "        'prop_llms_correct': row[f'prop_{the_correct_answer}'],\n",
    "        'true_human_or_GPT4': row['true_human_or_GPT4'],\n",
    "        'is_bad_strict': row['is_bad_strict'],\n",
    "        'is_bad_relaxed': row['is_bad_relaxed'],\n",
    "        'consensus_reason': row['consensus_reason']\n",
    "    }\n",
    "    ai_questions_llm_response_probs_df.append(new_row)\n",
    "\n",
    "ai_questions_llm_response_probs_df = pd.DataFrame(ai_questions_llm_response_probs_df).sort_values('prop_llms_correct')\n",
    "ai_questions_llm_response_probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 1, 11)\n",
    "plt.hist(\n",
    "    ai_questions_llm_response_probs_df.loc[ai_questions_llm_response_probs_df['is_bad_relaxed'] == 1, 'prop_llms_correct'],\n",
    "    bins=bins,\n",
    "    color='tab:red',\n",
    "    alpha=0.3,\n",
    "    label='Poor Quality AI-Generated Exam Items',\n",
    "    density=True\n",
    ")\n",
    "plt.hist(\n",
    "    ai_questions_llm_response_probs_df.loc[ai_questions_llm_response_probs_df['is_bad_relaxed'] == 0, 'prop_llms_correct'],\n",
    "    bins=bins,\n",
    "    color='tab:green',\n",
    "    alpha=0.3,\n",
    "    label='High Quality AI-Generated Exam Items',\n",
    "    density=True\n",
    ")\n",
    "plt.title('Distribution of model responses in realistic setting')\n",
    "plt.xlabel('Proportion of LLMs selecting the correct answer')\n",
    "plt.ylabel('Number of AI-generated exam items')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify AI-generated as good vs. bad based on proportion of LLMs that selected GPT4-chosen answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ability of LLM ensemble to detect poor quality AI-generated questions in realistic setting\n",
      "threshold=0.01, precision=0.52, recall=0.72\n",
      "threshold=0.11, precision=0.52, recall=0.72\n",
      "threshold=0.21, precision=0.52, recall=0.72\n",
      "threshold=0.31, precision=0.60, recall=0.50\n",
      "threshold=0.41, precision=0.60, recall=0.50\n",
      "threshold=0.51, precision=0.80, recall=0.22\n",
      "threshold=0.60, precision=0.80, recall=0.22\n",
      "threshold=0.70, precision=0.80, recall=0.22\n",
      "threshold=0.80, precision=0.75, recall=0.17\n",
      "threshold=0.90, precision=0.75, recall=0.17\n",
      "threshold=1.00, precision=0.00, recall=0.00\n",
      "AUROC = 0.7118055555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottyf/anaconda3/envs/youper/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Ability of LLM ensemble to detect poor quality AI-generated questions in realistic setting\")\n",
    "for thresh in np.linspace(0.01, 1, 11):\n",
    "    y_true = ai_questions_llm_response_probs_df['is_bad_relaxed']  # Whether the answer choice was incorrect\n",
    "    # y_pred = ai_questions_llm_response_probs_df['prop_llms_in_majority'] < thresh\n",
    "    y_pred = (1-ai_questions_llm_response_probs_df['prop_llms_correct']) > thresh\n",
    "    # y_pred = np.logical_and(\n",
    "    #     ai_questions_llm_response_probs_df['prop_llms_in_majority'] < thresh, \n",
    "    #     ai_questions_llm_response_probs_df['prop_llms_correct'] < thresh, \n",
    "    # )\n",
    "    precision = precision_score(y_true=y_true, y_pred=y_pred)\n",
    "    recall = recall_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f\"threshold={thresh:.2f}, precision={precision:.2f}, recall={recall:.2f}\")\n",
    "\n",
    "auroc = roc_auc_score(\n",
    "    ai_questions_llm_response_probs_df['is_bad_relaxed'], \n",
    "    1-ai_questions_llm_response_probs_df['prop_llms_correct']\n",
    ")\n",
    "print(f\"AUROC = {auroc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
